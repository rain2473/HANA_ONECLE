{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df6d7446",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykrx import stock\n",
    "from newsModel import newsCrawler\n",
    "from DB import DataFrameHandler\n",
    "from DB import AIModelHandler\n",
    "import requests, os, pickle, datetime\n",
    "import pandas as pd\n",
    "import urllib3\n",
    "urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)\n",
    "\n",
    "def calcStochasticK(df, n=14):\n",
    "    Numerator = df - df.rolling(window=n).min()\n",
    "    Denominator = df.rolling(window=n).max() - df.rolling(window=n).min()\n",
    "    result = (Numerator / Denominator * 100).round()\n",
    "    return result\n",
    "\n",
    "def makeStatisticsDF(ticker):\n",
    "    tmp = DataFrameHandler.findItems(\"ohlcv\", condition=f\"ISIN = '{ticker}' and WORK_DT > TO_DATE('2023/01/01','YYYY/MM/DD')\")\n",
    "    tmp = tmp.sort_values('WORK_DT').reset_index(drop=True)\n",
    "    tmp.drop(columns=['OPEN','HIGH','LOW',\"AMOUNT\",'UPDOWN'], inplace=True)\n",
    "    tmp['PRICE_CHANGE'] = tmp['CLOSE'].diff().fillna(0)\n",
    "    tmp['MOMENTUM'] = (tmp['CLOSE'] - tmp['CLOSE'].shift(10)).fillna(0)\n",
    "    tmp['OBV'] = ((tmp['PRICE_CHANGE'] != 0) * ((tmp['PRICE_CHANGE'] > 0) * 2 - 1) * tmp['VOLUME']).cumsum()\n",
    "    tmp['STOCHASTIC_K'] = calcStochasticK(tmp['CLOSE'])\n",
    "    tmp['STOCHASTIC_D'] = tmp['STOCHASTIC_K'].rolling(window=3).mean()\n",
    "    tmp['GAIN'] = tmp['PRICE_CHANGE'].apply(lambda x: max(x, 0))\n",
    "    tmp['LOSS'] = tmp['PRICE_CHANGE'].apply(lambda x: -min(x, 0))\n",
    "    tmp['EMA_GAIN'] = tmp['GAIN'].ewm(span=10, min_periods=10).mean()\n",
    "    tmp['EMA_LOSS'] = tmp['LOSS'].ewm(span=10, min_periods=10).mean()\n",
    "    tmp['RS'] = tmp['EMA_GAIN'] / tmp['EMA_LOSS']\n",
    "    tmp['RSI'] = 100 - (100 / (1 + tmp['RS']))\n",
    "    tmp.drop(columns=['CLOSE', 'VOLUME', 'PRICE_CHANGE', 'GAIN', 'LOSS', 'EMA_GAIN', 'EMA_LOSS','RS'], inplace=True)\n",
    "    tmp = tmp.round().dropna().reset_index(drop=True)\n",
    "    return tmp\n",
    "\n",
    "def labelDate():\n",
    "    df = stock.get_market_ohlcv('20230101', \"20240101\", '005930').reset_index().rename(columns={'날짜':'WORK_DT'})\n",
    "    tmp1 = df[['WORK_DT']]\n",
    "    tmp2 = DataFrameHandler.findItems(\"WORK_DATE\")\n",
    "    result = tmp1[~tmp1[\"WORK_DT\"].isin(tmp2[\"WORK_DT\"])].reset_index(drop=True)\n",
    "    result['DATE_LABEL'] = tmp2['DATE_LABEL'].max() + result.index + 1\n",
    "    input = result.copy(deep=True)\n",
    "    DataFrameHandler.insertItems('WORK_DATE', input)\n",
    "    return result\n",
    "\n",
    "def preprocessing2(ohlcv, fundamental, dateDF, fundamental_columns):\n",
    "    tmp_ohlcv = ohlcv.drop(columns=['AMOUNT'])\n",
    "    if fundamental_columns:\n",
    "        try:\n",
    "            tmp_fundamental = fundamental[[\"ISIN\",\"WORK_DT\", 'PBR','PER']]\n",
    "            total = pd.merge(tmp_ohlcv, tmp_fundamental, how='outer')\n",
    "            total.dropna(axis=0, inplace=True)\n",
    "        except:\n",
    "            total = tmp_ohlcv\n",
    "    else:\n",
    "        total = tmp_ohlcv\n",
    "    total.drop(columns=[\"ISIN\"], inplace=True)\n",
    "    total['WORK_DT'] = dateDF['DATE_LABEL']\n",
    "    return total\n",
    "\n",
    "def callTargetDataFrame(isin, date, fundamental_columns):\n",
    "    if DataFrameHandler.findItems('stock', columns='count(*)', condition=f\"ISIN='{isin}'\")['COUNT(*)'].to_list()[0] != 1:\n",
    "        raise Exception(\"ISIN NOT EXIST\")\n",
    "    dateDF = DataFrameHandler.findItems('WORK_DATE', condition=f\"WORK_DT >= to_date('{date}', 'YYYY/MM/DD')\")\n",
    "    ohlcv = DataFrameHandler.findItems('ohlcv', condition=f\"ISIN='{isin}' and WORK_DT >= to_date('{date}', 'YYYY/MM/DD')\", orderBy='WORK_DT')\n",
    "    fundamental = DataFrameHandler.findItems('fundamental', condition=f\"ISIN='{isin}' and WORK_DT >= to_date('{date}', 'YYYY/MM/DD')\", orderBy='WORK_DT')\n",
    "    result = preprocessing2(ohlcv, fundamental, dateDF, fundamental_columns)\n",
    "    return {\"result\" : result, \"date\" : dateDF}\n",
    "\n",
    "def callAIModels(isin):\n",
    "    if DataFrameHandler.findItems('stock', columns='count(*)', condition=f\"ISIN='{isin}'\")['COUNT(*)'].to_list()[0] != 1:\n",
    "        raise Exception(\"ISIN NOT EXIST\")\n",
    "    mainDirectory = os.path.join('PredictModel', 'models')\n",
    "    subDirectory = os.path.join(mainDirectory, isin)\n",
    "    fileDirectory = os.path.join(subDirectory, 'lastest.sav')\n",
    "    with open(fileDirectory, 'rb') as file:\n",
    "        models = file.read()\n",
    "    models = pickle.loads(models)\n",
    "    model_info = DataFrameHandler.findItems('MODEL_MANAGE', condition=f\"ISIN='{isin}'\", orderBy='VER_ID', desc=True)\n",
    "    models['version'] = model_info['VER_ID'][0]\n",
    "    return models\n",
    "\n",
    "def predict(isin, date, models):\n",
    "    datas = callTargetDataFrame(isin, date, models['fundamental_columns'])\n",
    "    dates = datas['date']\n",
    "    dataFrame = datas['result']\n",
    "    priceModel = models['priceModel']\n",
    "    updownModel = models['updownModel']\n",
    "    updownPredict = updownModel.predict(dataFrame)\n",
    "    try: \n",
    "        pricePredict = priceModel.predict(dataFrame)\n",
    "    except:\n",
    "        pricePredict = updownPredict\n",
    "    result = pd.DataFrame({\"PREDICT_PRICE\" : pricePredict, \"PREDICT_UPDOWN\" : updownPredict})\n",
    "    dataFrame['WORK_DT'] = dates['WORK_DT']\n",
    "    dataFrame['ISIN'] = isin\n",
    "    result = pd.concat([dataFrame, result], axis=1)\n",
    "    result['VER_ID'] = models['version']\n",
    "    result['PREDICT_PRICE'] = (result['PREDICT_PRICE'] > result['CLOSE']) * 1\n",
    "    result['PREDICT_UPDOWN'] = (result['PREDICT_UPDOWN'].round(2) > 0.5) * 1\n",
    "    return result\n",
    "\n",
    "def makePrediction(isin, date):\n",
    "    Model = callAIModels(isin)\n",
    "    df = callTargetDataFrame(isin, date, fundamental_columns = Model['fundamental_columns'])\n",
    "    df['result']['ANSWER'] = (df['result']['UPDOWN'].shift(-1) > 0) * 1\n",
    "    df['result'][\"WORK_DT\"] = df['date'][\"WORK_DT\"]\n",
    "    prediction = pd.merge(predict(isin, date, Model), df['result'][[\"WORK_DT\",'ANSWER']], how='outer')\n",
    "    prediction['CORRECT_PRICE'] = (prediction['PREDICT_PRICE'] == prediction['ANSWER']) * 1\n",
    "    prediction['CORRECT_UPDOWN'] = (prediction['PREDICT_UPDOWN'] == prediction['ANSWER']) * 1\n",
    "    prediction['WORK_DT'] = pd.to_datetime(prediction['WORK_DT'])\n",
    "    prediction = prediction[[\"ISIN\", \"WORK_DT\", 'VER_ID', \"PREDICT_PRICE\", \"PREDICT_UPDOWN\", \"CORRECT_PRICE\", \"CORRECT_UPDOWN\"]]\n",
    "    return prediction\n",
    "    \n",
    "def getIndex():\n",
    "    kosdaq_url = f'http://ecos.bok.or.kr/api/StatisticSearch/A5P1FVP5VX625OV2NVTA/json/kr/1/100000/802Y001/D/20130101/20240101/0089000'\n",
    "    rate_url = f'http://ecos.bok.or.kr/api/StatisticSearch/A5P1FVP5VX625OV2NVTA/json/kr/1/100000/722Y001/D/20130101/20240101/0101000'\n",
    "    kospi_url = f'http://ecos.bok.or.kr/api/StatisticSearch/A5P1FVP5VX625OV2NVTA/json/kr/1/100000/802Y001/D/20130101/20240101/0001000'\n",
    "    url = {\n",
    "        'kosdaq_url' : kosdaq_url,\n",
    "        'rate_url' : rate_url,\n",
    "        'kospi_url' : kospi_url\n",
    "    }\n",
    "    code = {\n",
    "        'kospi_url' : 1,\n",
    "        'kosdaq_url' : 2,\n",
    "        'rate_url' : 3\n",
    "    }\n",
    "    result = pd.DataFrame([])\n",
    "    for input in ['kospi_url', 'kosdaq_url', 'rate_url']:\n",
    "        response = requests.get(url[input], verify=False)\n",
    "        value = []\n",
    "        time = []\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            IDX_CODE = [code[input]] * data['StatisticSearch']['list_total_count']\n",
    "            for i in range(data['StatisticSearch']['list_total_count']):\n",
    "                value.append(data['StatisticSearch']['row'][i]['DATA_VALUE'])\n",
    "                time.append(data['StatisticSearch']['row'][i]['TIME'])\n",
    "            \n",
    "            tmp = pd.DataFrame({'WORK_DT' : time, 'IDX_CODE' : IDX_CODE, 'VALUE' : value})\n",
    "            result = pd.concat([result, tmp])\n",
    "        else:\n",
    "            print(f\"Failed to fetch data from {url}. Status code: {response.status_code}\")\n",
    "            result = None\n",
    "\n",
    "    result['WORK_DT'] = result['WORK_DT'].str[:4] + '-' + result['WORK_DT'].str[4:6] + '-' + result['WORK_DT'].str[6:8]\n",
    "    result['WORK_DT'] = pd.to_datetime(result['WORK_DT'], format='%Y-%m-%d')\n",
    "    return result\n",
    "\n",
    "def calcNewsScore(isin, start = '2023/09/01', end = None):\n",
    "    news = pd.DataFrame([])\n",
    "    work_dts = AIModelHandler.selectWorkDates(start = start)\n",
    "    for work_dt in work_dts:\n",
    "        work_dt = work_dt.date()\n",
    "        news = pd.concat([news, AIModelHandler.getNewsScore(isin, work_dt)])\n",
    "    news = news[['ISIN', 'WORK_DT', 'MENTION_SCORE', 'POSITIVE_SCORE']]\n",
    "    news.fillna(0, inplace=True)\n",
    "    news['WORK_DT'] = news['WORK_DT'].astype('datetime64[ns]')\n",
    "    news['POSITIVE_SCORE'] = ((news['POSITIVE_SCORE'] + 100) / 2).round().astype('int')\n",
    "    return news\n",
    "\n",
    "def calcPredictScore(isin, start = '2023/09/01', end = None):\n",
    "    return DataFrameHandler.findItems('predict', columns=[\"isin, work_dt, PREDICT_PRICE * 10 as price_score, PREDICT_UPDOWN * 10  as updown_score\"], condition=f\"isin = '{isin}' and work_dt >= TO_DATE('{start}', 'YYYY/MM/DD')\")\n",
    "\n",
    "def calcStatisticsScore(isin, start = '2023/09/01', end = None):\n",
    "    statistics = DataFrameHandler.findItems('statistics', condition=f\"isin = '{isin}' and work_dt >= (SELECT TO_DATE('{start}', 'YYYY/MM/DD') - 20 AS WORK_DT FROM DUAL)\")\n",
    "    statistics['RSI_SCORE'] = calcStochasticK(statistics['RSI'])\n",
    "    statistics['OBV_SCORE'] = calcStochasticK(statistics['OBV'])\n",
    "    statistics['STOCHASTIC_SCORE'] = calcStochasticK(statistics['STOCHASTIC_D'])\n",
    "    statistics['MOMENTUM_SCORE'] = calcStochasticK(statistics['MOMENTUM'])\n",
    "    statistics = statistics[statistics['WORK_DT']>='2023/09/01'][['ISIN', 'WORK_DT', 'RSI_SCORE', 'OBV_SCORE', 'STOCHASTIC_SCORE', 'MOMENTUM_SCORE']]\n",
    "    statistics.fillna(0, inplace=True)\n",
    "    statistics['RSI_SCORE'] = statistics['RSI_SCORE'].astype(int)\n",
    "    statistics['OBV_SCORE'] = statistics['OBV_SCORE'].astype(int)\n",
    "    statistics['STOCHASTIC_SCORE'] = statistics['STOCHASTIC_SCORE'].astype(int)\n",
    "    statistics['MOMENTUM_SCORE'] = statistics['MOMENTUM_SCORE'].astype(int)\n",
    "    return statistics\n",
    "\n",
    "def calcScore(isin, start = '2023/09/01', end = None):\n",
    "    predict = calcPredictScore(isin, start = start, end = end)\n",
    "    statistics = calcStatisticsScore(isin, start = start, end = end)\n",
    "    news = calcNewsScore(isin, start = start, end = end)\n",
    "    result = pd.merge(pd.merge(news, predict, how='outer'), statistics, how='outer') \n",
    "    result['AI_SCORE'] = (result[['PRICE_SCORE', 'UPDOWN_SCORE', 'MENTION_SCORE', 'POSITIVE_SCORE']].sum(axis=1) / 220 * 100)\n",
    "    result['STATISTICS_SCORE'] = (result[['RSI_SCORE', 'OBV_SCORE', 'STOCHASTIC_SCORE', 'MOMENTUM_SCORE']].sum(axis=1) / 400 * 100)\n",
    "    result['TOTAL_SCORE'] = (result[['PRICE_SCORE', 'UPDOWN_SCORE', 'MENTION_SCORE', 'POSITIVE_SCORE', 'RSI_SCORE', 'OBV_SCORE', 'STOCHASTIC_SCORE', 'MOMENTUM_SCORE']].sum(axis=1) / 620 * 100)\n",
    "    result = result.round().astype({'AI_SCORE': 'int', 'STATISTICS_SCORE': 'int', 'TOTAL_SCORE': 'int'})\n",
    "    return result\n",
    "\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1dfcc3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tickers = AIModelHandler.selectAllStock()\n",
    "work_date = DataFrameHandler.findItems(\"work_date\", condition=\"work_dt > to_date('2023/09/25','yyyy/mm/dd')\")\n",
    "daily_index = getIndex()\n",
    "daily_index = daily_index[daily_index[\"WORK_DT\"].isin(work_date['WORK_DT'])]\n",
    "# DataFrameHandler.insertItems('daily_index', daily_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a567d96c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>WORK_DT</th>\n",
       "      <th>DATE_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2023-09-26</td>\n",
       "      <td>2645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2023-09-27</td>\n",
       "      <td>2646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2023-10-04</td>\n",
       "      <td>2647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2023-10-05</td>\n",
       "      <td>2648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-10-06</td>\n",
       "      <td>2649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     WORK_DT  DATE_LABEL\n",
       "0 2023-09-26        2645\n",
       "1 2023-09-27        2646\n",
       "2 2023-10-04        2647\n",
       "3 2023-10-05        2648\n",
       "4 2023-10-06        2649"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "work_date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f707f79",
   "metadata": {},
   "outputs": [],
   "source": [
    "failed = []\n",
    "result_ohlcv = pd.DataFrame([])\n",
    "result_fundamental = pd.DataFrame([])\n",
    "for  work_dt in work_date['WORK_DT'].dt.strftime(\"%Y%m%d\").to_list():\n",
    "    try:\n",
    "        ohlcv1 = stock.get_market_ohlcv(work_dt)\n",
    "        fundamental1 = stock.get_market_fundamental(work_dt)\n",
    "        ohlcv2 = stock.get_market_ohlcv(work_dt, market = \"KOSDAQ\")\n",
    "        fundamental2 = stock.get_market_fundamental(work_dt, market = \"KOSDAQ\")\n",
    "        ohlcv = pd.concat([ohlcv1, ohlcv2]).reset_index()\n",
    "        fundamental = pd.concat([fundamental1, fundamental2]).reset_index()\n",
    "        ohlcv['WORK_DT'] = pd.to_datetime(work_dt)\n",
    "        fundamental['WORK_DT'] = pd.to_datetime(work_dt)\n",
    "        ohlcv = ohlcv[ohlcv['티커'].isin(tickers)]\n",
    "        fundamental = fundamental[fundamental['티커'].isin(tickers)]\n",
    "        ohlcv = ohlcv.rename(columns={'티커':'ISIN', '시가':'OPEN', '고가':'HIGH', '저가':'LOW', '종가':'CLOSE', '거래량':'VOLUME', '거래대금':'AMOUNT', '등락률':'UPDOWN'})\n",
    "        fundamental = fundamental.rename(columns={'티커':'ISIN'})\n",
    "        result_ohlcv = pd.concat([result_ohlcv, ohlcv])\n",
    "        result_fundamental = pd.concat([result_fundamental, fundamental])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        failed.append(work_dt)\n",
    "\n",
    "DataFrameHandler.insertItems('OHLCV', result_ohlcv)\n",
    "DataFrameHandler.insertItems('FUNDAMENTAL', result_fundamental)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "45a1eb60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORA-00001: unique constraint (RAIN2473.PK_STATISTICS) violated\n",
      "여까진ㄱㅊ\n"
     ]
    }
   ],
   "source": [
    "result_statistics = pd.DataFrame([])\n",
    "result_prediction = pd.DataFrame([])\n",
    "\n",
    "for i, ticker in enumerate(tickers):\n",
    "    try:\n",
    "        statistics = makeStatisticsDF(ticker)\n",
    "        statistics = statistics[statistics[\"WORK_DT\"].isin(work_date['WORK_DT'])]\n",
    "        prediction = makePrediction(ticker, '2023/09/25')\n",
    "\n",
    "        result_statistics = pd.concat([result_statistics, statistics])\n",
    "        result_prediction = pd.concat([result_prediction, prediction])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        failed.append(ticker)\n",
    "input_statistics = result_statistics.copy(deep=True)\n",
    "input_prediction = result_prediction.copy(deep=True)\n",
    "DataFrameHandler.insertItems('tmp_statistics', input_statistics)\n",
    "DataFrameHandler.mergeTable('statistics', 'tmp_statistics', [\"ISIN\", \"WORK_DT\"])\n",
    "DataFrameHandler.insertItems('tmp_predict', input_prediction)\n",
    "DataFrameHandler.mergeTable('predict', 'tmp_predict', [\"ISIN\", \"WORK_DT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87e97849",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ORA-00001: unique constraint (RAIN2473.PK_NEWS) violated\n"
     ]
    }
   ],
   "source": [
    "result_news = pd.DataFrame([])\n",
    "\n",
    "for i, ticker in enumerate(tickers):\n",
    "    try:\n",
    "        news = newsCrawler.getNewsData(ticker, \"2023/09/26\")\n",
    "\n",
    "        result_news = pd.concat([result_news, news])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        failed.append(ticker)\n",
    "\n",
    "input_news = result_news.copy(deep=True)\n",
    "DataFrameHandler.insertItems('tmp_news', input_news)\n",
    "DataFrameHandler.mergeTable('news', 'tmp_news', [\"ISIN\", \"NEWS_ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fb07182b",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_score = pd.DataFrame([])\n",
    "for i, ticker in enumerate(tickers):\n",
    "    try:\n",
    "        score = calcScore(ticker, start = '2023/09/01')\n",
    "        score = score[score[\"WORK_DT\"].isin(work_date['WORK_DT'])]\n",
    "        result_score = pd.concat([result_score, score])\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        failed.append(ticker)\n",
    "\n",
    "result_score.dropna(inplace=True)\n",
    "input_score = result_score.copy(deep=True)\n",
    "DataFrameHandler.insertItems(\"tmp_ONECLE_SCORE\", input_score)\n",
    "DataFrameHandler.mergeTable('ONECLE_SCORE', 'tmp_ONECLE_SCORE', [\"ISIN\", \"WORK_DT\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "430dc4f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DataFrameHandler.mergeTable('ONECLE_SCORE', 'tmp_ONECLE_SCORE', [\"ISIN\", \"WORK_DT\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
